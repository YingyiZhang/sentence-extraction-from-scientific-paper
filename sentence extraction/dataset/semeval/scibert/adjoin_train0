0	start%%%using natural language processing , we carried out a trend survey on japanese natural language processing studies that have been done over the last ten years .%%%we determined the changes in the number of papers published for each research organization and on each research area as well as the relationship between research organizations and research areas .	MT
1	using natural language processing , we carried out a trend survey on japanese natural language processing studies that have been done over the last ten years .%%%we determined the changes in the number of papers published for each research organization and on each research area as well as the relationship between research organizations and research areas .%%%this paper is useful for both recognizing trends in japanese nl ##p and constructing a method of supporting trend surveys using nl ##p .	O
2	we determined the changes in the number of papers published for each research organization and on each research area as well as the relationship between research organizations and research areas .%%%this paper is useful for both recognizing trends in japanese nl ##p and constructing a method of supporting trend surveys using nl ##p .%%%end	MT
3	start%%%we propose a draft scheme of the model formal ##izing the structure of communicative context in dialogue interaction .%%%the relationships between the interacting partners are considered as system of three automata representing the partners of the dialogue and environment .	T
4	we propose a draft scheme of the model formal ##izing the structure of communicative context in dialogue interaction .%%%the relationships between the interacting partners are considered as system of three automata representing the partners of the dialogue and environment .%%%end	O
5	start%%%this paper examines what kind of similarity between words can be represented by what kind of word vectors in the vector space model .%%%through two experiments , three methods for constructing word vectors , i . e . , ls ##a - based , co ##occurrence - based and dictionary - based methods , were compared in terms of the ability to represent two kinds of similarity , i . e . , taxonomic similarity and associative similarity .	M
6	this paper examines what kind of similarity between words can be represented by what kind of word vectors in the vector space model .%%%through two experiments , three methods for constructing word vectors , i . e . , ls ##a - based , co ##occurrence - based and dictionary - based methods , were compared in terms of the ability to represent two kinds of similarity , i . e . , taxonomic similarity and associative similarity .%%%the result of the comparison was that the dictionary - based word vectors better reflect taxonomic similarity , while the ls ##a - based and the co ##occurrence - based word vectors better reflect associative similarity .	MT
7	through two experiments , three methods for constructing word vectors , i . e . , ls ##a - based , co ##occurrence - based and dictionary - based methods , were compared in terms of the ability to represent two kinds of similarity , i . e . , taxonomic similarity and associative similarity .%%%the result of the comparison was that the dictionary - based word vectors better reflect taxonomic similarity , while the ls ##a - based and the co ##occurrence - based word vectors better reflect associative similarity .%%%end	MT
8	start%%%in this paper , we present a novel training method for a localized phrase - based prediction model for statistical machine translation - lr ##b - sm ##t - rr ##b - .%%%the model predicts blocks with orientation to handle local phrase re - ordering .	MT
9	in this paper , we present a novel training method for a localized phrase - based prediction model for statistical machine translation - lr ##b - sm ##t - rr ##b - .%%%the model predicts blocks with orientation to handle local phrase re - ordering .%%%we use a maximum likelihood criterion to train a log - linear block big ##ram model which uses real - valued features - lr ##b - e . g . a language model score - rr ##b - as well as binary features based on the block identities themselves , e . g . block big ##ram features .	MT
10	the model predicts blocks with orientation to handle local phrase re - ordering .%%%we use a maximum likelihood criterion to train a log - linear block big ##ram model which uses real - valued features - lr ##b - e . g . a language model score - rr ##b - as well as binary features based on the block identities themselves , e . g . block big ##ram features .%%%our training algorithm can easily handle millions of features .	MT
11	we use a maximum likelihood criterion to train a log - linear block big ##ram model which uses real - valued features - lr ##b - e . g . a language model score - rr ##b - as well as binary features based on the block identities themselves , e . g . block big ##ram features .%%%our training algorithm can easily handle millions of features .%%%the best system obtains a 18 . 6 % improvement over the baseline on a standard arabic - english translation task .	MT
12	our training algorithm can easily handle millions of features .%%%the best system obtains a 18 . 6 % improvement over the baseline on a standard arabic - english translation task .%%%statistical language modeling remains a challenging task , in particular for morphologically rich languages .	T
13	the best system obtains a 18 . 6 % improvement over the baseline on a standard arabic - english translation task .%%%statistical language modeling remains a challenging task , in particular for morphologically rich languages .%%%end	T
14	start%%%recently , new approaches based on factor ##ed language models have been developed to address this problem .%%%these models provide principle ##d ways of including additional conditioning variables other than the preceding words , such as morphological or syntactic features .	M
15	recently , new approaches based on factor ##ed language models have been developed to address this problem .%%%these models provide principle ##d ways of including additional conditioning variables other than the preceding words , such as morphological or syntactic features .%%%however , the number of possible choices for model parameters creates a large space of models that can not be searched exhaustive ##ly .	T
16	these models provide principle ##d ways of including additional conditioning variables other than the preceding words , such as morphological or syntactic features .%%%however , the number of possible choices for model parameters creates a large space of models that can not be searched exhaustive ##ly .%%%this paper presents an entirely data - driven model selection procedure based on genetic search , which is shown to outperform both knowledge - based and random selection procedures on two different language modeling tasks - lr ##b - arabic and turkish - rr ##b - .	O
17	however , the number of possible choices for model parameters creates a large space of models that can not be searched exhaustive ##ly .%%%this paper presents an entirely data - driven model selection procedure based on genetic search , which is shown to outperform both knowledge - based and random selection procedures on two different language modeling tasks - lr ##b - arabic and turkish - rr ##b - .%%%the prc adaptive knowledge - based text understanding system - lr ##b - pak ##tu ##s - rr ##b - has been under development as an independent research and development project at prc since 1984 .	MT
18	this paper presents an entirely data - driven model selection procedure based on genetic search , which is shown to outperform both knowledge - based and random selection procedures on two different language modeling tasks - lr ##b - arabic and turkish - rr ##b - .%%%the prc adaptive knowledge - based text understanding system - lr ##b - pak ##tu ##s - rr ##b - has been under development as an independent research and development project at prc since 1984 .%%%end	M
19	start%%%the objective is a generic system of tools , including a core english lexicon , grammar , and concept representations , for building natural language processing - lr ##b - nl ##p - rr ##b - systems for text understanding .%%%systems built with pak ##tu ##s are intended to generate input to knowledge based systems ord ##ata base systems .	MT
20	the objective is a generic system of tools , including a core english lexicon , grammar , and concept representations , for building natural language processing - lr ##b - nl ##p - rr ##b - systems for text understanding .%%%systems built with pak ##tu ##s are intended to generate input to knowledge based systems ord ##ata base systems .%%%input to the nl ##p system is typically derived from an existing electronic message stream , such as a news wire .	MT
21	systems built with pak ##tu ##s are intended to generate input to knowledge based systems ord ##ata base systems .%%%input to the nl ##p system is typically derived from an existing electronic message stream , such as a news wire .%%%pak ##tu ##s supports the adaptation of the generic core to a variety of domains : jin ##tac ##cs messages , rain ##form messages , news reports about a specific type of event , such as financial transfers or terror ##ist acts , etc . , by acquiring sub ##language and domain - specific grammar , words , conceptual mappings , and discourse patterns .	M
22	input to the nl ##p system is typically derived from an existing electronic message stream , such as a news wire .%%%pak ##tu ##s supports the adaptation of the generic core to a variety of domains : jin ##tac ##cs messages , rain ##form messages , news reports about a specific type of event , such as financial transfers or terror ##ist acts , etc . , by acquiring sub ##language and domain - specific grammar , words , conceptual mappings , and discourse patterns .%%%the long - term goal is a system that can support the processing of relatively long discourse ##s in domains that are fairly broad with a high rate of success .	MT
23	pak ##tu ##s supports the adaptation of the generic core to a variety of domains : jin ##tac ##cs messages , rain ##form messages , news reports about a specific type of event , such as financial transfers or terror ##ist acts , etc . , by acquiring sub ##language and domain - specific grammar , words , conceptual mappings , and discourse patterns .%%%the long - term goal is a system that can support the processing of relatively long discourse ##s in domains that are fairly broad with a high rate of success .%%%end	T
24	start%%%this paper describes the understanding process of the spatial descriptions in japanese .%%%in order to understand the described world , the authors try to reconstruct the geometric model of the global scene from the scen ##ic descriptions drawing a space .	M
25	this paper describes the understanding process of the spatial descriptions in japanese .%%%in order to understand the described world , the authors try to reconstruct the geometric model of the global scene from the scen ##ic descriptions drawing a space .%%%it is done by an experimental computer program spr ##int , which takes natural language texts and produces a model of the described world .	MT
26	in order to understand the described world , the authors try to reconstruct the geometric model of the global scene from the scen ##ic descriptions drawing a space .%%%it is done by an experimental computer program spr ##int , which takes natural language texts and produces a model of the described world .%%%to reconstruct the model , the authors extract the qualitative spatial constraints from the text , and represent them as the numerical constraints on the spatial attributes of the entities .	MT
27	it is done by an experimental computer program spr ##int , which takes natural language texts and produces a model of the described world .%%%to reconstruct the model , the authors extract the qualitative spatial constraints from the text , and represent them as the numerical constraints on the spatial attributes of the entities .%%%this makes it possible to express the vague ##ness of the spatial concepts and to derive the maximally plausible interpretation from a chunk of information accumulated as the constraints .	MT
28	to reconstruct the model , the authors extract the qualitative spatial constraints from the text , and represent them as the numerical constraints on the spatial attributes of the entities .%%%this makes it possible to express the vague ##ness of the spatial concepts and to derive the maximally plausible interpretation from a chunk of information accumulated as the constraints .%%%the interpretation reflects the temporary belief about the world .	T
29	this makes it possible to express the vague ##ness of the spatial concepts and to derive the maximally plausible interpretation from a chunk of information accumulated as the constraints .%%%the interpretation reflects the temporary belief about the world .%%%end	O
30	start%%%in this paper , we describe a phrase - based uni ##gram model for statistical machine translation that uses a much simpler set of model parameters than similar phrase - based models .%%%the units of translation are blocks - pairs of phrases .	MT
31	in this paper , we describe a phrase - based uni ##gram model for statistical machine translation that uses a much simpler set of model parameters than similar phrase - based models .%%%the units of translation are blocks - pairs of phrases .%%%during decoding , we use a block uni ##gram model and a word - based trig ##ram language model .	O
32	the units of translation are blocks - pairs of phrases .%%%during decoding , we use a block uni ##gram model and a word - based trig ##ram language model .%%%during training , the blocks are learned from source interval projections using an underlying word alignment .	M
33	during decoding , we use a block uni ##gram model and a word - based trig ##ram language model .%%%during training , the blocks are learned from source interval projections using an underlying word alignment .%%%we show experimental results on block selection criteria based on uni ##gram counts and phrase length .	M
34	during training , the blocks are learned from source interval projections using an underlying word alignment .%%%we show experimental results on block selection criteria based on uni ##gram counts and phrase length .%%%end	M
35	start%%%state - of - the - art question answering - lr ##b - qa - rr ##b - systems are very sensitive to variations in the phr ##asing of an information need .%%%finding the preferred language for such a need is a valuable task .	M
36	state - of - the - art question answering - lr ##b - qa - rr ##b - systems are very sensitive to variations in the phr ##asing of an information need .%%%finding the preferred language for such a need is a valuable task .%%%we investigate that claim by adopting a simple mt - based parap ##hr ##asing technique and evaluating qa system performance on parap ##hr ##ased questions .	O
37	finding the preferred language for such a need is a valuable task .%%%we investigate that claim by adopting a simple mt - based parap ##hr ##asing technique and evaluating qa system performance on parap ##hr ##ased questions .%%%we found a potential increase of 35 % in mr ##r with respect to the original question .	M
38	we investigate that claim by adopting a simple mt - based parap ##hr ##asing technique and evaluating qa system performance on parap ##hr ##ased questions .%%%we found a potential increase of 35 % in mr ##r with respect to the original question .%%%in the chinese language , a verb may have its dependent ##s on its left , right or on both sides .	M
39	we found a potential increase of 35 % in mr ##r with respect to the original question .%%%in the chinese language , a verb may have its dependent ##s on its left , right or on both sides .%%%the ambiguity resolution of right - side dependencies is essential for dependency parsing of sentences with two or more verbs .	O
40	in the chinese language , a verb may have its dependent ##s on its left , right or on both sides .%%%the ambiguity resolution of right - side dependencies is essential for dependency parsing of sentences with two or more verbs .%%%end	MT
41	start%%%previous works on shift - reduce dependency parser ##s may not guarantee the connectivity of a dependency tree due to their weakness at resolving the right - side dependencies .%%%this paper proposes a two - phase shift - reduce dependency parser based on svm learning .	MT
42	previous works on shift - reduce dependency parser ##s may not guarantee the connectivity of a dependency tree due to their weakness at resolving the right - side dependencies .%%%this paper proposes a two - phase shift - reduce dependency parser based on svm learning .%%%the left - side dependent ##s and right - side nominal dependent ##s are detected in phase i , and right - side verbal dependent ##s are decided in phase ii .	M
43	this paper proposes a two - phase shift - reduce dependency parser based on svm learning .%%%the left - side dependent ##s and right - side nominal dependent ##s are detected in phase i , and right - side verbal dependent ##s are decided in phase ii .%%%in experimental evaluation , our proposed method outperforms previous shift - reduce dependency parser ##s for the chin ##e language , showing improvement of dependency accuracy by 10 . 08 % .	O
44	the left - side dependent ##s and right - side nominal dependent ##s are detected in phase i , and right - side verbal dependent ##s are decided in phase ii .%%%in experimental evaluation , our proposed method outperforms previous shift - reduce dependency parser ##s for the chin ##e language , showing improvement of dependency accuracy by 10 . 08 % .%%%recent advances in automatic speech recognition technology have put the goal of naturally sound ##ing dialog systems within reach .	M
45	in experimental evaluation , our proposed method outperforms previous shift - reduce dependency parser ##s for the chin ##e language , showing improvement of dependency accuracy by 10 . 08 % .%%%recent advances in automatic speech recognition technology have put the goal of naturally sound ##ing dialog systems within reach .%%%end	M
46	start%%%however , the improved speech recognition has brought to light a new problem : as dialog systems understand more of what the user tells them , they need to be more sophisticated at responding to the user .%%%the issue of system response to users has been extensively studied by the natural language generation community , though rarely in the context of dialog systems .	MT
47	however , the improved speech recognition has brought to light a new problem : as dialog systems understand more of what the user tells them , they need to be more sophisticated at responding to the user .%%%the issue of system response to users has been extensively studied by the natural language generation community , though rarely in the context of dialog systems .%%%we show how research in generation can be adapted to dialog systems , and how the high cost of hand - cra ##ft ##ing knowledge - based generation systems can be overcome by employing machine learning techniques .	M
48	the issue of system response to users has been extensively studied by the natural language generation community , though rarely in the context of dialog systems .%%%we show how research in generation can be adapted to dialog systems , and how the high cost of hand - cra ##ft ##ing knowledge - based generation systems can be overcome by employing machine learning techniques .%%%end	MT
49	start%%%this paper presents a word segmentation system in france telec ##om r & d beijing , which uses a unified approach to word breaking and oo ##v identification .%%%the output can be customized to meet different segmentation standards through the application of an ordered list of transformation .	MT
50	this paper presents a word segmentation system in france telec ##om r & d beijing , which uses a unified approach to word breaking and oo ##v identification .%%%the output can be customized to meet different segmentation standards through the application of an ordered list of transformation .%%%the system participated in all the tracks of the segmentation bak ##e ##off - - pk - open , pk - closed , as - open , as - closed , hk - open , hk - closed , ms ##r - open and ms ##r - closed - - and achieved the state - of - the - art performance in ms ##r - open , ms ##r - close and pk - open tracks .	M
51	the output can be customized to meet different segmentation standards through the application of an ordered list of transformation .%%%the system participated in all the tracks of the segmentation bak ##e ##off - - pk - open , pk - closed , as - open , as - closed , hk - open , hk - closed , ms ##r - open and ms ##r - closed - - and achieved the state - of - the - art performance in ms ##r - open , ms ##r - close and pk - open tracks .%%%analysis of the results shows that each component of the system contributed to the scores .	O
52	the system participated in all the tracks of the segmentation bak ##e ##off - - pk - open , pk - closed , as - open , as - closed , hk - open , hk - closed , ms ##r - open and ms ##r - closed - - and achieved the state - of - the - art performance in ms ##r - open , ms ##r - close and pk - open tracks .%%%analysis of the results shows that each component of the system contributed to the scores .%%%end	O
53	start%%%in this paper i will argue for a model of grammatical processing that is based on uniform processing and knowledge sources .%%%the main feature of this model is to view parsing and generation as two strongly interle ##aved tasks performed by a single parametri ##zed deduc ##tion process .	MT
54	in this paper i will argue for a model of grammatical processing that is based on uniform processing and knowledge sources .%%%the main feature of this model is to view parsing and generation as two strongly interle ##aved tasks performed by a single parametri ##zed deduc ##tion process .%%%it will be shown that this view supports flexible and efficient natural language processing .	MT
55	the main feature of this model is to view parsing and generation as two strongly interle ##aved tasks performed by a single parametri ##zed deduc ##tion process .%%%it will be shown that this view supports flexible and efficient natural language processing .%%%this report describes paul , a computer text generation system designed to create cohe ##sive text through the use of lexical substitutions .	T
56	it will be shown that this view supports flexible and efficient natural language processing .%%%this report describes paul , a computer text generation system designed to create cohe ##sive text through the use of lexical substitutions .%%%specifically , this system is designed to deterministic ##ally choose between prono ##min ##ali ##zation , super ##ordinate substitution , and definite noun phrase re ##iter ##ation .	MT
57	this report describes paul , a computer text generation system designed to create cohe ##sive text through the use of lexical substitutions .%%%specifically , this system is designed to deterministic ##ally choose between prono ##min ##ali ##zation , super ##ordinate substitution , and definite noun phrase re ##iter ##ation .%%%the system identifies a strength of antec ##ede ##nc ##e recovery for each of the lexical substitutions , and matches them against the strength of potential antec ##ede ##nc ##e of each element in the text to select the proper substitutions for these elements .	T
58	specifically , this system is designed to deterministic ##ally choose between prono ##min ##ali ##zation , super ##ordinate substitution , and definite noun phrase re ##iter ##ation .%%%the system identifies a strength of antec ##ede ##nc ##e recovery for each of the lexical substitutions , and matches them against the strength of potential antec ##ede ##nc ##e of each element in the text to select the proper substitutions for these elements .%%%end	T
59	start%%%this paper considers the problem of automatic assessment of local coherence .%%%we present a novel entity - based representation of discourse which is inspired by center ##ing theory and can be computed automatically from raw text .	T
60	this paper considers the problem of automatic assessment of local coherence .%%%we present a novel entity - based representation of discourse which is inspired by center ##ing theory and can be computed automatically from raw text .%%%we view coherence assessment as a ranking learning problem and show that the proposed discourse representation supports the effective learning of a ranking function .	M
61	we present a novel entity - based representation of discourse which is inspired by center ##ing theory and can be computed automatically from raw text .%%%we view coherence assessment as a ranking learning problem and show that the proposed discourse representation supports the effective learning of a ranking function .%%%our experiments demonstrate that the induced model achieves significantly higher accuracy than a state - of - the - art coherence model .	MT
62	we view coherence assessment as a ranking learning problem and show that the proposed discourse representation supports the effective learning of a ranking function .%%%our experiments demonstrate that the induced model achieves significantly higher accuracy than a state - of - the - art coherence model .%%%end	M
63	start%%%sentiment classification seeks to identify a piece of text according to its author ' s general feeling toward their subject , be it positive or negative .%%%traditional machine learning techniques have been applied to this problem with reasonable success , but they have been shown to work well only when there is a good match between the training and test data with respect to topic .	M
64	sentiment classification seeks to identify a piece of text according to its author ' s general feeling toward their subject , be it positive or negative .%%%traditional machine learning techniques have been applied to this problem with reasonable success , but they have been shown to work well only when there is a good match between the training and test data with respect to topic .%%%end	M
65	start%%%this paper demonstrates that match with respect to domain and time is also important , and presents preliminary experiments with training data labeled with emo ##tic ##ons , which has the potential of being independent of domain , topic and time .%%%we argue in favor of the the use of labeled directed graph to represent various types of linguistic structures , and illustrate how this allows one to view nl ##p tasks as graph transformations .	O
66	this paper demonstrates that match with respect to domain and time is also important , and presents preliminary experiments with training data labeled with emo ##tic ##ons , which has the potential of being independent of domain , topic and time .%%%we argue in favor of the the use of labeled directed graph to represent various types of linguistic structures , and illustrate how this allows one to view nl ##p tasks as graph transformations .%%%we present a general method for learning such transformations from an annotated corpus and describe experiments with two applications of the method : identification of non - local dep ##enen ##ci ##es - lr ##b - using penn tree ##bank data - rr ##b - and semantic role labeling - lr ##b - using proposition bank data - rr ##b - .	MT
67	we argue in favor of the the use of labeled directed graph to represent various types of linguistic structures , and illustrate how this allows one to view nl ##p tasks as graph transformations .%%%we present a general method for learning such transformations from an annotated corpus and describe experiments with two applications of the method : identification of non - local dep ##enen ##ci ##es - lr ##b - using penn tree ##bank data - rr ##b - and semantic role labeling - lr ##b - using proposition bank data - rr ##b - .%%%this paper investigates some computational problems associated with probabilistic translation models that have recently been adopted in the literature on machine translation .	T
68	we present a general method for learning such transformations from an annotated corpus and describe experiments with two applications of the method : identification of non - local dep ##enen ##ci ##es - lr ##b - using penn tree ##bank data - rr ##b - and semantic role labeling - lr ##b - using proposition bank data - rr ##b - .%%%this paper investigates some computational problems associated with probabilistic translation models that have recently been adopted in the literature on machine translation .%%%end	MT
69	start%%%these models can be viewed as pairs of probabilistic context - free grammars working in a ` synchronous ' way .%%%two hardness results for the class np are reported , along with an exponential time lower - bound for certain classes of algorithms that are currently used in the literature .	M
70	these models can be viewed as pairs of probabilistic context - free grammars working in a ` synchronous ' way .%%%two hardness results for the class np are reported , along with an exponential time lower - bound for certain classes of algorithms that are currently used in the literature .%%%in this paper , we present a fully automated extraction system , named inte ##x , to identify gene and protein interactions in biomedical text .	O
71	two hardness results for the class np are reported , along with an exponential time lower - bound for certain classes of algorithms that are currently used in the literature .%%%in this paper , we present a fully automated extraction system , named inte ##x , to identify gene and protein interactions in biomedical text .%%%our approach is based on first splitting complex sentences into simple cla ##usal structures made up of syntactic roles .	MT
72	in this paper , we present a fully automated extraction system , named inte ##x , to identify gene and protein interactions in biomedical text .%%%our approach is based on first splitting complex sentences into simple cla ##usal structures made up of syntactic roles .%%%end	M
73	start%%%then , tagging biological entities with the help of biomedical and linguistic ontologies .%%%finally , extracting complete interactions by analyzing the matching contents of syntactic roles and their linguistic ##ally significant combinations .	MT
74	then , tagging biological entities with the help of biomedical and linguistic ontologies .%%%finally , extracting complete interactions by analyzing the matching contents of syntactic roles and their linguistic ##ally significant combinations .%%%our extraction system handles complex sentences and extracts multiple and nested interactions specified in a sentence .	MT
75	finally , extracting complete interactions by analyzing the matching contents of syntactic roles and their linguistic ##ally significant combinations .%%%our extraction system handles complex sentences and extracts multiple and nested interactions specified in a sentence .%%%experimental evaluations with two other state of the art extraction systems indicate that the inte ##x system achieves better performance without the labor intensive pattern engineering requirement .	MT
76	our extraction system handles complex sentences and extracts multiple and nested interactions specified in a sentence .%%%experimental evaluations with two other state of the art extraction systems indicate that the inte ##x system achieves better performance without the labor intensive pattern engineering requirement .%%%end	M
77	start%%%the inter ##ling ##ual approach to mt has been repeatedly advocated by researchers originally interested in natural language understanding who take machine translation to be one possible application .%%%however , not only the ambiguity but also the vague ##ness which every natural language inevitably has leads this approach into essential difficulties .	MT
78	the inter ##ling ##ual approach to mt has been repeatedly advocated by researchers originally interested in natural language understanding who take machine translation to be one possible application .%%%however , not only the ambiguity but also the vague ##ness which every natural language inevitably has leads this approach into essential difficulties .%%%in contrast , our project , the mu - project , adopts the transfer approach as the basic framework of mt .	O
79	however , not only the ambiguity but also the vague ##ness which every natural language inevitably has leads this approach into essential difficulties .%%%in contrast , our project , the mu - project , adopts the transfer approach as the basic framework of mt .%%%this paper describes the detailed construction of the transfer phase of our system from japanese to english , and gives some examples of problems which seem difficult to treat in the inter ##ling ##ual approach .	MT
80	in contrast , our project , the mu - project , adopts the transfer approach as the basic framework of mt .%%%this paper describes the detailed construction of the transfer phase of our system from japanese to english , and gives some examples of problems which seem difficult to treat in the inter ##ling ##ual approach .%%%end	MT
81	start%%%the basic design principles of the transfer phase of our system have already been mentioned in - lr ##b - 1 - rr ##b - - lr ##b - 2 - rr ##b - .%%%some of the principles which are relevant to the topic of this paper are : - lr ##b - a - rr ##b - multiple layer of grammars - lr ##b - b - rr ##b - multiple layer presentation - lr ##b - c - rr ##b - lexicon driven processing - lr ##b - d - rr ##b - form - oriented dictionary description .	O
82	the basic design principles of the transfer phase of our system have already been mentioned in - lr ##b - 1 - rr ##b - - lr ##b - 2 - rr ##b - .%%%some of the principles which are relevant to the topic of this paper are : - lr ##b - a - rr ##b - multiple layer of grammars - lr ##b - b - rr ##b - multiple layer presentation - lr ##b - c - rr ##b - lexicon driven processing - lr ##b - d - rr ##b - form - oriented dictionary description .%%%this paper also shows how these principles are realized in the current system .	M
83	some of the principles which are relevant to the topic of this paper are : - lr ##b - a - rr ##b - multiple layer of grammars - lr ##b - b - rr ##b - multiple layer presentation - lr ##b - c - rr ##b - lexicon driven processing - lr ##b - d - rr ##b - form - oriented dictionary description .%%%this paper also shows how these principles are realized in the current system .%%%sentence boundary detection in speech is important for enrich ##ing speech recognition output , making it easier for humans to read and downstream modules to process .	O
84	this paper also shows how these principles are realized in the current system .%%%sentence boundary detection in speech is important for enrich ##ing speech recognition output , making it easier for humans to read and downstream modules to process .%%%in previous work , we have developed hidden markov model - lr ##b - hmm - rr ##b - and maximum entropy - lr ##b - max ##ent - rr ##b - classifiers that integrate textual and prosodic knowledge sources for detecting sentence boundaries .	MT
85	sentence boundary detection in speech is important for enrich ##ing speech recognition output , making it easier for humans to read and downstream modules to process .%%%in previous work , we have developed hidden markov model - lr ##b - hmm - rr ##b - and maximum entropy - lr ##b - max ##ent - rr ##b - classifiers that integrate textual and prosodic knowledge sources for detecting sentence boundaries .%%%end	MT
86	start%%%in this paper , we evaluate the use of a conditional random field - lr ##b - crf - rr ##b - for this task and relate results with this model to our prior work .%%%we evaluate across two corpora - lr ##b - conversation ##al telephone speech and broadcast news speech - rr ##b - on both human transcription ##s and speech recognition output .	M
87	in this paper , we evaluate the use of a conditional random field - lr ##b - crf - rr ##b - for this task and relate results with this model to our prior work .%%%we evaluate across two corpora - lr ##b - conversation ##al telephone speech and broadcast news speech - rr ##b - on both human transcription ##s and speech recognition output .%%%in general , our crf model yields a lower error rate than the hmm and max - ent models on the nist sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three - way voting among the classifiers .	O
88	we evaluate across two corpora - lr ##b - conversation ##al telephone speech and broadcast news speech - rr ##b - on both human transcription ##s and speech recognition output .%%%in general , our crf model yields a lower error rate than the hmm and max - ent models on the nist sentence boundary detection task in speech , although it is interesting to note that the best results are achieved by three - way voting among the classifiers .%%%end	MT
89	start%%%this probably occurs because each model has different strengths and weaknesses for modeling the knowledge sources .%%%topical blog post retrieval is the task of ranking blog posts with respect to their relevance for a given topic .	T
90	this probably occurs because each model has different strengths and weaknesses for modeling the knowledge sources .%%%topical blog post retrieval is the task of ranking blog posts with respect to their relevance for a given topic .%%%to improve topical blog post retrieval we incorporate textual credibility indicators in the retrieval process .	T
91	topical blog post retrieval is the task of ranking blog posts with respect to their relevance for a given topic .%%%to improve topical blog post retrieval we incorporate textual credibility indicators in the retrieval process .%%%end	MT
92	start%%%we consider two groups of indicators : post level - lr ##b - determined using information about individual blog posts only - rr ##b - and blog level - lr ##b - determined using information from the underlying blog ##s - rr ##b - .%%%we describe how to estimate these indicators and how to integrate them into a retrieval approach based on language models .	M
93	we consider two groups of indicators : post level - lr ##b - determined using information about individual blog posts only - rr ##b - and blog level - lr ##b - determined using information from the underlying blog ##s - rr ##b - .%%%we describe how to estimate these indicators and how to integrate them into a retrieval approach based on language models .%%%experiments on the tre ##c blog track test set show that both groups of credibility indicators significantly improve retrieval effectiveness ; the best performance is achieved when combining them .	MT
94	we describe how to estimate these indicators and how to integrate them into a retrieval approach based on language models .%%%experiments on the tre ##c blog track test set show that both groups of credibility indicators significantly improve retrieval effectiveness ; the best performance is achieved when combining them .%%%determine ##rs play an important role in convey ##ing the meaning of an utterance , but they have often been disreg ##arded , perhaps because it seemed more important to devi ##se methods to grasp the global meaning of a sentence , even if not in a precise way .	T
95	experiments on the tre ##c blog track test set show that both groups of credibility indicators significantly improve retrieval effectiveness ; the best performance is achieved when combining them .%%%determine ##rs play an important role in convey ##ing the meaning of an utterance , but they have often been disreg ##arded , perhaps because it seemed more important to devi ##se methods to grasp the global meaning of a sentence , even if not in a precise way .%%%end	MT
96	start%%%another problem with determine ##rs is their inherent ambiguity .%%%in this paper we propose a logical formalism , which , among other things , is suitable for representing determine ##rs without forcing a particular interpretation when their meaning is still not clear .	MT
97	another problem with determine ##rs is their inherent ambiguity .%%%in this paper we propose a logical formalism , which , among other things , is suitable for representing determine ##rs without forcing a particular interpretation when their meaning is still not clear .%%%we provide a unified account of sentence - level and text - level anaph ##ora within the framework of a dependency - based grammar model .	MT
98	in this paper we propose a logical formalism , which , among other things , is suitable for representing determine ##rs without forcing a particular interpretation when their meaning is still not clear .%%%we provide a unified account of sentence - level and text - level anaph ##ora within the framework of a dependency - based grammar model .%%%end	MT
99	start%%%criteria for anaph ##ora resolution within sentence boundaries rep ##hr ##ase major concepts from gb ' s binding theory , while those for text - level anaph ##ora incorporate an adapted version of a gros ##z - sid ##ner - style focus model .%%%gloss ##er is designed to support reading and learning to read in a foreign language .	MT
100	criteria for anaph ##ora resolution within sentence boundaries rep ##hr ##ase major concepts from gb ' s binding theory , while those for text - level anaph ##ora incorporate an adapted version of a gros ##z - sid ##ner - style focus model .%%%gloss ##er is designed to support reading and learning to read in a foreign language .%%%end	MT
101	start%%%there are four language pairs currently supported by gloss ##er : english - bul ##gar ##ian , english - est ##onian , english - hung ##arian and french - dutch .%%%the program is operational on uni ##x and windows ' 95 platforms , and has undergone a pilot user - study .	M
102	there are four language pairs currently supported by gloss ##er : english - bul ##gar ##ian , english - est ##onian , english - hung ##arian and french - dutch .%%%the program is operational on uni ##x and windows ' 95 platforms , and has undergone a pilot user - study .%%%a demonstration - lr ##b - in uni ##x - rr ##b - for applied natural language processing emphasizes components put to novel technical uses in intelligent computer - assisted morphological analysis - lr ##b - ica ##ll - rr ##b - , including disambig ##uated morphological analysis and lemma ##tized indexing for an aligned bilingual corpus of word examples .	M
103	the program is operational on uni ##x and windows ' 95 platforms , and has undergone a pilot user - study .%%%a demonstration - lr ##b - in uni ##x - rr ##b - for applied natural language processing emphasizes components put to novel technical uses in intelligent computer - assisted morphological analysis - lr ##b - ica ##ll - rr ##b - , including disambig ##uated morphological analysis and lemma ##tized indexing for an aligned bilingual corpus of word examples .%%%end	MT
104	start%%%we suggest a new goal and evaluation criterion for word similarity measures .%%%the new criterion meaning - entail ##ing substitu ##tab ##ility fits the needs of semantic - oriented nl ##p applications and can be evaluated directly - lr ##b - independent of an application - rr ##b - at a good level of human agreement .	MT
105	we suggest a new goal and evaluation criterion for word similarity measures .%%%the new criterion meaning - entail ##ing substitu ##tab ##ility fits the needs of semantic - oriented nl ##p applications and can be evaluated directly - lr ##b - independent of an application - rr ##b - at a good level of human agreement .%%%motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word similarity results , proposing an objective measure for evaluating feature vector quality .	MT
106	the new criterion meaning - entail ##ing substitu ##tab ##ility fits the needs of semantic - oriented nl ##p applications and can be evaluated directly - lr ##b - independent of an application - rr ##b - at a good level of human agreement .%%%motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word similarity results , proposing an objective measure for evaluating feature vector quality .%%%finally , a novel feature weighting and selection function is presented , which yields superior feature vectors and better word similarity performance .	MT
107	motivated by this semantic criterion we analyze the empirical quality of distributional word feature vectors and its impact on word similarity results , proposing an objective measure for evaluating feature vector quality .%%%finally , a novel feature weighting and selection function is presented , which yields superior feature vectors and better word similarity performance .%%%combination methods are an effective way of improving system performance .	MT
108	finally , a novel feature weighting and selection function is presented , which yields superior feature vectors and better word similarity performance .%%%combination methods are an effective way of improving system performance .%%%this paper examines the benefits of system combination for unsupervised ws ##d .	MT
109	combination methods are an effective way of improving system performance .%%%this paper examines the benefits of system combination for unsupervised ws ##d .%%%end	T
110	start%%%we investigate several voting - and arb ##iter - based combination strategies over a diverse pool of unsupervised ws ##d systems .%%%our combination methods rely on predominant senses which are derived automatically from raw text .	M
111	we investigate several voting - and arb ##iter - based combination strategies over a diverse pool of unsupervised ws ##d systems .%%%our combination methods rely on predominant senses which are derived automatically from raw text .%%%experiments using the sem ##cor and sense ##val - 3 data sets demonstrate that our ensembles yield significantly better results when compared with state - of - the - art .	M
112	our combination methods rely on predominant senses which are derived automatically from raw text .%%%experiments using the sem ##cor and sense ##val - 3 data sets demonstrate that our ensembles yield significantly better results when compared with state - of - the - art .%%%we investigate independent and relevant event - based extract ##ive mut ##li - document summar ##ization approaches .	M
113	experiments using the sem ##cor and sense ##val - 3 data sets demonstrate that our ensembles yield significantly better results when compared with state - of - the - art .%%%we investigate independent and relevant event - based extract ##ive mut ##li - document summar ##ization approaches .%%%in this paper , events are defined as event terms and associated event elements .	M
114	we investigate independent and relevant event - based extract ##ive mut ##li - document summar ##ization approaches .%%%in this paper , events are defined as event terms and associated event elements .%%%end	O
115	start%%%with independent approach , we identify important contents by frequency of events .%%%with relevant approach , we identify important contents by page ##rank algorithm on the event map constructed from documents .	MT
116	with independent approach , we identify important contents by frequency of events .%%%with relevant approach , we identify important contents by page ##rank algorithm on the event map constructed from documents .%%%experimental results are encouraging .	MT
117	with relevant approach , we identify important contents by page ##rank algorithm on the event map constructed from documents .%%%experimental results are encouraging .%%%we present the first application of the head - driven statistical parsing model of collins - lr ##b - 1999 - rr ##b - as a simultaneous language model and parser for large - vocabulary speech recognition .	O
118	experimental results are encouraging .%%%we present the first application of the head - driven statistical parsing model of collins - lr ##b - 1999 - rr ##b - as a simultaneous language model and parser for large - vocabulary speech recognition .%%%the model is adapted to an online left to right chart - parser for word lattices , integrating acoustic , n - gram , and parser probabilities .	MT
119	we present the first application of the head - driven statistical parsing model of collins - lr ##b - 1999 - rr ##b - as a simultaneous language model and parser for large - vocabulary speech recognition .%%%the model is adapted to an online left to right chart - parser for word lattices , integrating acoustic , n - gram , and parser probabilities .%%%the parser uses structural and lexical dependencies not considered by n - gram models , conditioning recognition on more linguistic ##ally - grounded relationships .	M
120	the model is adapted to an online left to right chart - parser for word lattices , integrating acoustic , n - gram , and parser probabilities .%%%the parser uses structural and lexical dependencies not considered by n - gram models , conditioning recognition on more linguistic ##ally - grounded relationships .%%%experiments on the wall street journal tree ##bank and lattice corpora show word error rates competitive with the standard n - gram language model while extracting additional structural information useful for speech understanding .	MT
121	the parser uses structural and lexical dependencies not considered by n - gram models , conditioning recognition on more linguistic ##ally - grounded relationships .%%%experiments on the wall street journal tree ##bank and lattice corpora show word error rates competitive with the standard n - gram language model while extracting additional structural information useful for speech understanding .%%%end	MT
122	start%%%both rhetor ##ical structure and punct ##uation have been helpful in discourse processing .%%%based on a corpus annotation project , this paper reports the disc ##urs ##ive usage of 6 chinese punct ##uation marks in news commentary texts : colon , dash , ellip ##sis , excl ##ama ##tion mark , question mark , and semic ##olo ##n .	MT
123	both rhetor ##ical structure and punct ##uation have been helpful in discourse processing .%%%based on a corpus annotation project , this paper reports the disc ##urs ##ive usage of 6 chinese punct ##uation marks in news commentary texts : colon , dash , ellip ##sis , excl ##ama ##tion mark , question mark , and semic ##olo ##n .%%%the rhetor ##ical patterns of these marks are compared against patterns around cue phrases in general .	MT
124	based on a corpus annotation project , this paper reports the disc ##urs ##ive usage of 6 chinese punct ##uation marks in news commentary texts : colon , dash , ellip ##sis , excl ##ama ##tion mark , question mark , and semic ##olo ##n .%%%the rhetor ##ical patterns of these marks are compared against patterns around cue phrases in general .%%%results show that these chinese punct ##uation marks , though fewer in number than cue phrases , are easy to identify , have strong correlation with certain relations , and can be used as distinctive indicators of nuclear ##ity in chinese texts .	O
125	the rhetor ##ical patterns of these marks are compared against patterns around cue phrases in general .%%%results show that these chinese punct ##uation marks , though fewer in number than cue phrases , are easy to identify , have strong correlation with certain relations , and can be used as distinctive indicators of nuclear ##ity in chinese texts .%%%end	M
126	start%%%this paper describes three relatively domain - independent capabilities recently added to the param ##ax spoken language understanding system : non - monotonic reasoning , implicit reference resolution , and database query parap ##hr ##ase .%%%in addition , we discuss the results of the february 1992 ati ##s benchmark tests .	MT
127	this paper describes three relatively domain - independent capabilities recently added to the param ##ax spoken language understanding system : non - monotonic reasoning , implicit reference resolution , and database query parap ##hr ##ase .%%%in addition , we discuss the results of the february 1992 ati ##s benchmark tests .%%%we describe a variation on the standard evaluation metric which provides a more tightly controlled measure of progress .	M
128	in addition , we discuss the results of the february 1992 ati ##s benchmark tests .%%%we describe a variation on the standard evaluation metric which provides a more tightly controlled measure of progress .%%%finally , we briefly describe an experiment which we have done in extending the n - best speech / language integration architecture to improving oc ##r accuracy .	O
129	we describe a variation on the standard evaluation metric which provides a more tightly controlled measure of progress .%%%finally , we briefly describe an experiment which we have done in extending the n - best speech / language integration architecture to improving oc ##r accuracy .%%%end	T
